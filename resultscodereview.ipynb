{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Reinforcement Learning Based Approach to Demand Prediction and Location Optimization of Electric Vehicle Charging Stations in New York"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In recent years, significant advances have been made in smart grid technology and renewable energies in order to reduce reliance on fossil fuels, which emit harmful greenhouse gases. Along with these advances in power generation and distribution, electric vehicles (EVs) have also been increasingly adopted in cities throughout the U.S. However, effective strategies are necessary to build charging infrastructure to meet this new demand for EVs, and there are still many challenges that hinder the further expansion of EV usage. \n",
    "\n",
    "One issue is the convenience and accessibility of charging stations - the distribution of charging stations is not always effective, and with variations in charging demand and battery sizes, there is a need for charging stations to account for a rising number of EV users while maintaining efficiency. More substantial changes to usage patterns due to population changes or even the COVID-19 pandemic can also add to the difficulty of predicting where charging stations would be most effective. Thus, charging station infrastructure can still be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has been substantial research in the realm of EVs and optimizing placement of charging stations, but there is not as much existing work that has addressed the specific issue of placing charging stations with a reinforcement learning approach. EV charging demand is predicted with Canonical Correlation Analysis (CCA) in Gopalakrishnan et al. (2016), utilizing auxiliary data such as Points of Interest (PoI), which are nearby buildings and institutions that could influence demand, and traffic density. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Almaghrebi et al. (2020), EV charging demand is predicted with supervised machine learning methods such as gradient boosting, support vector machines, and random forest as displayed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=“center”>\n",
    "    <center><img src=demand.png width=“400\" height=“400” /></center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, Wagner et al. (2013) optimizes EV charging station locations by sectioning off areas in Amsterdam that could serve as potential charging spots, forming a grid. The attractiveness of placing charge points in these areas is based on data from nearby points of interest, which is closely related to charging demand. The example below illustrates the idea of creating a grid and analyzing points of interest around potential charging locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=“center”>\n",
    "    <center><img src=grid.png width=“400\" height=“400” /></center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reinforcement learning based model would allow an agent to account for many different factors, such as energy consumption, charging times, budget, or coverage, while automatically navigating the environment and learning an optimal placement of charging stations in the areas with the highest demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning (RL) Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinforcement Learning is an area of machine learning that focuses on having an autonomous agent interact with an environment and learn to make decisions on its own. By performing actions in  the environment, the agent receives feedback from the environment--its reward--and learns to improve future actions. RL problems are typically modeled with the **Markov Decision Process (MDP)** shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=“center”>\n",
    "    <center><img src=markov.png width=“400\" height=“400” /></center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the standard RL setting, the agent will continually receive a state $s_t$ from the environment and will follow a policy $\\pi$ in order to select an action $a_t$, with the goal of maximizing the return from each state. This return incorporates a reward $r_t$ which can be obtained from certain actions, and is represented by \n",
    "\n",
    "$$Q^{\\pi}(s,a)=\\mathbb{E}[R_t|s_t=s,a_t=a], $$ \n",
    "\n",
    "also known as the **action-value function**. $R_t$ denotes the reward function, and is defined by \n",
    "\n",
    "$$R_t=\\sum_{i=0}^{\\infty} \\gamma^i r_{t+i},$$\n",
    "\n",
    "where $r_t$ is the expected reward at time step $t$ and $\\gamma$ is the **discount factor**, which determines how much importance the agent will place on future rewards compared to current rewards. The **optimal value function**, $Q^{*}(s,a)$, represents the maximum possible action value and is defined by \n",
    "\n",
    "$$Q^{*}(s,a)=\\max Q^{\\pi}(s,a).$$ \n",
    "\n",
    "One of the most common RL algorithms, Q-learning, is a **value-based method** that attempts to directly estimate the optimal value function. This is done by iteratively minimizing a sequence of loss functions and updating the value function based on the reward received from moving to the next state. Other RL methods build an explicit representation of the agent's policy, known as **policy-based methods**, and still others combine an the value-based approach with the policy-based approach into **actor-critic** type algorithms. In our proposed framework, we experiment with multiple types of these RL algorithms to optimize charging station locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "Our approach to improve the accessibility of these charging stations is to utilize reinforcement learning to predict the expected demand at multiple locations, and to then choose optimal locations to deploy new charging stations to satisfy that demand. The goal is to maximize the coverage of new charging stations (meaning that the station is accessible to EVs within a certain distance) and minimize total costs using a predetermined budget as to ensure an efficient use of resources. Our model should also be able to adapt to new data that may show increases or decreases in overall EV usage and demand. By analyzing a variety of factors, the model will learn a useful strategy for placing charging stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan to set up an environment as described above and test multiple RL algorithms, taking into account the following factors:\n",
    "- Historical usage data from existing charging stations\n",
    "- Nearby points that could influence demand (e.g. schools, shops, hospitals, etc.)\n",
    "- Traffic data from nearby intersections\n",
    "- Average range of electric vehicles\n",
    "- Costs of deploying a new charging station (e.g. licensing, number and type of charging slots)\n",
    "- Charging station wait times and pricing\n",
    "- EV network\n",
    "- Other factors that could influence demand (hourly changes, peak demand, seasonal changes)\n",
    "\n",
    "We plan to use two different models throughout our methods. The first model will predict energy demand by using the above factors as inputs, using supervised and unsupervised machine learning methods to find correlations in the data. This model will result in a heatmap that shows areas with high and low demand across a given region in New York. \n",
    "\n",
    "Then, our RL model will interact with this heatmap in addition to other factors in order to learn the best locations to place charging stations to meet the charging demand. After placing down a charging station, the first model will be called again to update the heatmap with new demand, given that there is a new charging station at the location selected by the RL agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our demand prediction model, we will attempt to predict the energy demand given the traffic density, EV density, number of ports, and the surrounding POIs. We test various machine learning methods from the Scikit-learn library, including Random Forest, Gradient Boosting, and Bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('demand_data.csv')\n",
    "# Drop the extra features that we don't want to use to predict\n",
    "df = df.drop(['Latitude', 'Longitude', 'Nearby Stations', 'ZIP', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a `train_test_split` to split up the data and train the models. The target feature will be energy demand, but in the future we will also incorporate charge duration into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['Energy Demand','Charge Duration'], axis=1)\n",
    "y = df['Energy Demand']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out the scores for each model. Boosting seems to have the best performance with an R^2 score of 0.85. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting: 0.8530294266405338\n",
      "Random Forest: 0.7913328870992996\n",
      "Bagging: 0.7123862373255617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "def gboost(X_train, y_train):\n",
    "    boost = GradientBoostingRegressor()\n",
    "    boost.fit(X_train, y_train)\n",
    "    return boost\n",
    "\n",
    "def randforest(X_train, y_train):\n",
    "    forest = RandomForestRegressor()\n",
    "    forest.fit(X_train, y_train)\n",
    "    return forest\n",
    "\n",
    "def bagreg(X_train, y_train):\n",
    "    bag = BaggingRegressor()\n",
    "    bag.fit(X_train, y_train)\n",
    "    return bag\n",
    "\n",
    "boost = gboost(X_train, y_train)\n",
    "print('Gradient Boosting: ' + str(boost.score(X_test, y_test)))\n",
    "\n",
    "forest = randforest(X_train, y_train)\n",
    "print('Random Forest: ' + str(forest.score(X_test, y_test)))\n",
    "\n",
    "bag = bagreg(X_train, y_train)\n",
    "print('Bagging: ' + str(bag.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an understanding of what the model is doing, we can look at the relative importance it places on each feature. Based on this visual, it appears that the boosting model heavily favors EV density and Traffic Density as predictors of demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature Importance (MDI)')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = boost.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, np.array(df.columns)[sorted_idx])\n",
    "plt.title('Feature Importance (MDI)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we continue to tune these models to increase their scores, we will hopefully test on large enough areas (rather than just Albany) so that the influence of POIs is more apparent in the models. We use this model in our reinforcement learning framework to predict demand in our environment and contribute to the reward function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build a model for Deep Q-Learning, we must define and create and environment. Our environment consists of a 2D grid (26 x 26) that contains energy demand values in each cell that remain static. These demand values will be one of the primary factors in calculating the agent's reward. In the upcoming weeks, we will add complexity to this model so that there is more than just demand at play (charging wait times, changing map of demand)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we select a section of Albany County with a reasonable amount of roads, charging stations, and POIs to train on. Using a bounding box on OpenStreetMap, we can split up the region into a 26 x 26 grid and assign traffic densities and POIs to each cell. Each grid cell is 250m on one side. Then, we use our demand prediction model to give each cell a realistic demand value assuming we construct a Level 2 EV charger in that cell. The resulting heatmap of the selected region is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=“center”>\n",
    "    <center><img src=dededewdw.png width=“400\" height=“400” /></center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build a Q-learning model based on this grid, where an agent has to navigate its way to the spots with the highest demand. Our RL agent will have five possible actions: one action for a directional movement to the north, south, east, or west, and one action that places a \"charging station\" at its current location. The goal of the agent is to move around to find the areas with highest demand, then place charging stations in those areas. Each episode, the agent will be placed in a random location on the grid, and rewards will be given in the following ways: if the agent places a charging station, the reward is the demand value at that location, and if the agent decides to move, the reward is proportional to the difference in demand between the agent's previous location and its next location. This will incentivize the agent to move towards \"good\" squares. This implementation is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pickle\n",
    "from matplotlib import style \n",
    "import time \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the grid (previously saved with pickle)\n",
    "import pickle\n",
    "\n",
    "with open ('C__Users_shankarpadmanabhan_Documents_CS378_pickle_test1.data', 'rb') as f:\n",
    "    new_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define variables and constants that we will use throughout the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy, deepcopy\n",
    "\n",
    "HM_EPISODES = 15000 # num of total episodes (used 50000 episodes during actual training)\n",
    "SHOW_EVERY = 1000 # display data every 1000 episodes\n",
    "SIZE = 26\n",
    "epsilon = 0.9\n",
    "EPS_DECAY = 0.99999\n",
    "place_prob = 0.8 # decreases the chance that the agent will place a station when picking a random action based on epsilon\n",
    "DEMAND_DECREASE = 0.5 # after placing a station, attractiveness at that point goes down\n",
    "TOTAL_PLACEMENTS = 10 # total num of chargers to place down\n",
    "grid = deepcopy(new_data)\n",
    "\n",
    "start_q_table = None\n",
    "LEARNING_RATE = 0.1 \n",
    "DISCOUNT = 0.95 # discount factor for Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown below is the Agent class, which is a representation of our RL agent. An important thing to note is that when the agent places a charging station, the demand at that location decreases by a factor of `DEMAND_DECREASE`. Additionally, every other cell in the grid has its demand decreased by an amount proportional to its distance from the cell with the charging station, simulating the process of placing a charger in the real world and having it decrease demand across a certain area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL Agent class\n",
    "class Agent:\n",
    "    # Initialize agent to random spot on the grid\n",
    "    def __init__(self):\n",
    "        self.x = np.random.randint(0, SIZE)\n",
    "        self.y = np.random.randint(0, SIZE)\n",
    "        self.count = TOTAL_PLACEMENTS\n",
    "    \n",
    "    # Get the number of stations left to place\n",
    "    def get_count(self):\n",
    "        return self.count\n",
    "\n",
    "    # Can move up, down, left, right, or place station at current location    \n",
    "    def action(self, choice):\n",
    "        if choice == 0:\n",
    "            self.move(x=1, y=0)\n",
    "        elif choice == 1:\n",
    "            self.move(x=-1, y=0)\n",
    "        elif choice == 2:\n",
    "            self.move(x=0, y=1)\n",
    "        elif choice == 3:\n",
    "            self.move(x=0, y=-1)\n",
    "        elif choice == 4:\n",
    "            self.place_station(self.x, self.y)\n",
    "\n",
    "    # Update agent's grid position\n",
    "    def move(self, x=False, y=False):\n",
    "        if not x:\n",
    "            self.x += np.random.randint(-1, 2)\n",
    "        else:\n",
    "            self.x += x\n",
    "        if not y:\n",
    "            self.y += np.random.randint(-1, 2)\n",
    "        else:\n",
    "            self.y += y\n",
    "\n",
    "        # Account for hitting a wall\n",
    "        if self.x < 0:\n",
    "            self.x = 0\n",
    "        elif self.x > SIZE - 1:\n",
    "            self.x = SIZE - 1\n",
    "        if self.y < 0:\n",
    "            self.y = 0\n",
    "        elif self.y > SIZE - 1:\n",
    "            self.y = SIZE - 1\n",
    "    \n",
    "    # Place station at the current location\n",
    "    def place_station(self, x=False, y=False):\n",
    "        value = grid[x][y] * DEMAND_DECREASE # decrease the current grid cell's demand \n",
    "\n",
    "        # For every cell in the grid, decrease its demand proportional to its distance from the current cell\n",
    "        # This simulates the fact that placing chargers alleviates demand across an area\n",
    "        for r in range(0, SIZE):\n",
    "            for c in range(0, SIZE):\n",
    "                dist = math.sqrt((x - r) ** 2 + (y - c) ** 2) # find Euclidean distance\n",
    "                decrease = 1 / ((dist + 1) ** dist) # factor to decrease demand by\n",
    "                current_val = grid[r][c]\n",
    "                grid[r][c] = current_val - current_val * decrease # update the cell with decreased demand\n",
    "        \n",
    "        grid[x][y] = value \n",
    "        self.count -= 1 # decrement the total stations left to place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the Q-table, which is the basis of Q-learning. Each observation and action in this environment has a Q-value that judges how \"good\" an action is in a certain state, and the agent's goal is to continuously update these Q-values to eventually learn the best actions for every state. At the beginning, these Q-values are randomly initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Q table\n",
    "if start_q_table is None:\n",
    "    q_table = {}\n",
    "    # For every possible observation of the agent (each cell in the grid), \n",
    "    # randomly initialize Q-values\n",
    "    for x1 in range(-SIZE + 1, SIZE):\n",
    "        for y1 in range(-SIZE + 1, SIZE):\n",
    "            q_table[((x1, y1))] = [np.random.uniform(-5, 0) for i in range(5)]\n",
    "else:\n",
    "    # or import an existing q table\n",
    "    with open(start_q_table, \"rb\") as f:\n",
    "        q_table = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the primary loop that performs the learning. The overall process is that the agent takes in an observation from the environment, selects an action, obtains a reward, and then updates its Q-values based on that reward. Additionally, there is a variable `epsilon` that essentially encourages the agent to perform more random actions during the initial training stages to \"explore\" the environment. As training continues, the epsilon value decreases and the agent gradually begins picking only the best actions based on its Q-table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on # 0, epsilon: 0.9\n",
      "1000 ep mean: nan\n",
      "on # 1000, epsilon: 0.8910448058217547\n",
      "1000 ep mean: 2948.267674537111\n",
      "on # 2000, epsilon: 0.8821787177576952\n",
      "1000 ep mean: 2980.156107652927\n",
      "on # 3000, epsilon: 0.8734008491827644\n",
      "1000 ep mean: 3126.5178728110855\n",
      "on # 4000, epsilon: 0.8647103222940146\n",
      "1000 ep mean: 3157.4293547348416\n",
      "on # 5000, epsilon: 0.8561062680228179\n",
      "1000 ep mean: 3150.251606424603\n",
      "on # 6000, epsilon: 0.8475878259479752\n",
      "1000 ep mean: 3217.5996734601754\n",
      "on # 7000, epsilon: 0.8391541442096618\n",
      "1000 ep mean: 3196.6161702068334\n",
      "on # 8000, epsilon: 0.8308043794242427\n",
      "1000 ep mean: 3214.5816985490806\n",
      "on # 9000, epsilon: 0.8225376965999297\n",
      "1000 ep mean: 3196.9499415373543\n",
      "on # 10000, epsilon: 0.814353269053287\n",
      "1000 ep mean: 3264.6568420994327\n",
      "on # 11000, epsilon: 0.8062502783265522\n",
      "1000 ep mean: 3202.7426276217534\n",
      "on # 12000, epsilon: 0.798227914105797\n",
      "1000 ep mean: 3258.256844856341\n",
      "on # 13000, epsilon: 0.790285374139891\n",
      "1000 ep mean: 3292.7816219826323\n",
      "on # 14000, epsilon: 0.7824218641602796\n",
      "1000 ep mean: 3302.9472078646013\n"
     ]
    }
   ],
   "source": [
    "episode_rewards = [] # track total rewards for each episode\n",
    "all_positions = [] # track positions of the agent, for debugging purposes\n",
    "ep_means = [] # track the means for every 1000 episodes\n",
    "\n",
    "# Main reinforcement learning loop\n",
    "for episode in range(HM_EPISODES):\n",
    "    positions = [] # track positions of the agent\n",
    "    player = Agent()\n",
    "\n",
    "    # Show data for each 1000 episodes\n",
    "    if episode % SHOW_EVERY == 0:\n",
    "        print(f\"on # {episode}, epsilon: {epsilon}\")\n",
    "        print(f\"{SHOW_EVERY} ep mean: {np.mean(episode_rewards[-SHOW_EVERY:])}\")\n",
    "        ep_means.append(np.mean(episode_rewards[-SHOW_EVERY:]))\n",
    "        positions.append((player.x, player.y))\n",
    "\n",
    "    episode_reward = 0\n",
    "\n",
    "    # Number of steps to take per episode (hard coded)\n",
    "    for i in range(300):\n",
    "        obs = (player.x, player.y) # observation of the agent = position\n",
    "        prev = grid[player.x][player.y] # set prev equal to agent's position before taking the action\n",
    "\n",
    "        # Epsilon-greedy (chance for the agent to choose a random action (explore)) \n",
    "        if np.random.random() > epsilon:\n",
    "            # choose best action based on q values\n",
    "            action = np.argmax(q_table[obs])\n",
    "\n",
    "        else:\n",
    "            # choose a random action, lower the chance of choosing to place a station\n",
    "            action = np.random.randint(0, 4)\n",
    "            if np.random.random() > place_prob:\n",
    "                 action = 4\n",
    "\n",
    "        # take an action\n",
    "        player.action(action)\n",
    "        \n",
    "        if action == 4:\n",
    "            # if placing a station, give a reward from the original grid\n",
    "            reward = grid[player.x][player.y]\n",
    "            positions.append((player.x, player.y))\n",
    "        else:\n",
    "            # if the agent moved, give a reward based on the difference in grid values from\n",
    "            # the previous cell to this cell (\"gradient\" to move to better locations)\n",
    "            reward = (grid[player.x][player.y] - prev)\n",
    "\n",
    "        # Updating Q-values\n",
    "        new_obs = (player.x, player.y)\n",
    "        max_future_q = np.max(q_table[new_obs])\n",
    "        current_q = q_table[obs][action]\n",
    "        new_q = (1 - LEARNING_RATE) * current_q + LEARNING_RATE * (reward + DISCOUNT * max_future_q)\n",
    "        q_table[obs][action] = new_q \n",
    "        \n",
    "\n",
    "        episode_reward += reward\n",
    "        # Stop the loop when all stations are placed\n",
    "        if player.get_count() == 0:\n",
    "            break\n",
    "    \n",
    "    if episode % SHOW_EVERY == 0:\n",
    "        all_positions.append(positions)\n",
    "    \n",
    "    # Reset map, boolean grid, update epsilon\n",
    "    grid = deepcopy(new_data)\n",
    "    episode_rewards.append(episode_reward)\n",
    "    if epsilon > 0.1:\n",
    "        epsilon *= EPS_DECAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Q-learning can be effective in smaller environments, it may not be the most effective approach as we add complexity and more dimensions to our reinforcement learning. As the training results show, there is some increase in the performance of the agent, but the learning is not quite stable or consistent. Increasing the length of each episode may help the agent to explore its surroundings more, as well as adding more epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot up the training data\n",
    "plt.plot([i for i in range(HM_EPISODES // SHOW_EVERY)], ep_means)\n",
    "plt.ylabel(f\"reward {SHOW_EVERY}ma\")\n",
    "plt.xlabel(\"episode #\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But with larger environments, Deep Q-Learning becomes more useful. Instead of needing a Q-table to store all possible Q-values, the Q-values for states and actions are predicted using a neural network and compared to target Q-values. There is also usually a second neural network, the target network, that is compared to the main network and is updated less frequently to increase stability. The Deep Q model also utilizes an experience replay memory, storing past experiences to then update the network after a certain amount of episodes. This improves the learning process because the weights of the neural network do not have to be updated after every experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-Learning Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is partially adapted from Renotte, N. OpenAI-Reinforcement-Learning-with-Custom-Environment (2021), GitHub repository, https://github.com/nicknochnack/OpenAI-Reinforcement-Learning-with-Custom-Environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Deep Q-Learning, we can use the same grid environment as before with the demand values in each cell. First, we will find the minimum and maximum demands, as well as the smallest and largest 10 demands which we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for arr in new_data:\n",
    "    for x in arr:\n",
    "        new_list.append(x)\n",
    "\n",
    "new_list.sort()\n",
    "min_single_demand = new_list[0]\n",
    "minimum = 0\n",
    "for x in range(0, 10):\n",
    "    minimum += new_list[x]\n",
    "\n",
    "new_list.sort(reverse=True)\n",
    "max_single_demand = new_list[0]\n",
    "maximum = 0\n",
    "for x in range(0, 10):\n",
    "    maximum += new_list[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can begin setting up our custom environment. In this environment, the action space is an ordered pair that represents each possible grid square. An action is defined as the agent selecting a grid square to place a charger in. The states of the environment that are observed by the agent is a list of 2 values: the current accumulated demand compared to the maximum possible demand, and the current accumulated \"coverage\" compared to the maximum possible coverage. These comparisons are performed by taking the mean squared error of the two values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, the coverage refers to the amount of grid cells that can be \"covered\" by placing a charging station. We represent this with another 2d grid where each cell has 3 possible values: a 0 means that the cell is not covered, a 1 means that the cell is covered by another charging station, and a 2 means that there is a charging station in that cell. To calculate the reward, the demand in the given cell is combined with the total increase in coverage gained from placing a station in that cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the terminal state for an episode is reached when the total cost of stations exceeds the total budget; in this case, the total budget and station costs are hard coded such that a maximum of 10 stations can be placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_GRID = new_data\n",
    "COVER_GRID = np.zeros([26, 26])\n",
    "MAX_DEMAND = maximum\n",
    "MIN_DEMAND = minimum\n",
    "MAX_SINGLE_DEMAND = max_single_demand\n",
    "MIN_SINGLE_DEMAND = min_single_demand\n",
    "MAX_COVERAGE = 260\n",
    "MIN_COVERAGE = 26\n",
    "STATION_COST = 1000\n",
    "TOTAL_BUDGET = 10000\n",
    "\n",
    "class ChargeEnv(Env):   \n",
    "    def __init__(self):\n",
    "        # Actions we can take - place a 2 or 4 port charger at a location in the grid      \n",
    "        self.action_space = spaces.Tuple((spaces.Discrete(26), spaces.Discrete(26)))\n",
    "        self.observation_space = spaces.Box(low=np.array([0, MIN_COVERAGE]), high=np.array([0, MAX_COVERAGE]), dtype='float64')\n",
    "        self.state = np.array([MAX_DEMAND, MAX_COVERAGE]) # loss from max demand, loss from max coverage\n",
    "        self.total_demand = 0\n",
    "        self.total_coverage = 0 \n",
    "        self.budget = TOTAL_BUDGET # total budget\n",
    "\n",
    "    def get_demand(self, action):\n",
    "        return MAIN_GRID[action[0]][action[1]]\n",
    "    \n",
    "    def inbounds(self, x, y):\n",
    "        return x >= 0 and x < len(COVER_GRID) and y >= 0 and y < len(COVER_GRID[0])\n",
    "\n",
    "    def update_coverages(self, action):\n",
    "        total = 0 if COVER_GRID[action[0]][action[1]] == 2 else 2\n",
    "        COVER_GRID[action[0]][action[1]] = 2\n",
    "        cover_size = 3\n",
    "        for i in range(action[0] - cover_size, action[0] + cover_size + 1):\n",
    "            for j in range(action[1] - cover_size, action[1] + cover_size + 1):\n",
    "                if self.inbounds(i, j):\n",
    "                    if COVER_GRID[action[0]][action[1]] == 0:\n",
    "                        COVER_GRID[action[0]][action[1]] = 1\n",
    "                        total += 1\n",
    "        return total\n",
    "    \n",
    "    def get_reward(self, action):\n",
    "        reward = -1\n",
    "        demand = 0\n",
    "        if COVER_GRID[action[0]][action[1]] != 2:\n",
    "            demand = self.get_demand(action)\n",
    "            demand = float((demand - MIN_SINGLE_DEMAND)) / float((MAX_SINGLE_DEMAND - MIN_SINGLE_DEMAND))\n",
    "            self.total_demand += self.get_demand(action)\n",
    "        reward = demand + float(self.update_coverages(action)) / float(MIN_COVERAGE)\n",
    "        return reward\n",
    "\n",
    "    def get_coverage(self, action):\n",
    "        total = 0\n",
    "        for row in COVER_GRID:\n",
    "            for x in row:\n",
    "                total += x\n",
    "        return total\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Calculate reward\n",
    "        reward = self.get_reward(action)\n",
    "        # Update variables\n",
    "        # FIX: don't update demand when placing in same spot\n",
    "        self.total_coverage = self.get_coverage(action)\n",
    "        self.state[0] = 0.5 * ((MAX_DEMAND - self.total_demand) ** 2)\n",
    "        self.state[1] = 0.5 * ((MAX_COVERAGE - self.total_coverage) ** 2)\n",
    "        self.budget -= STATION_COST\n",
    "\n",
    "        \n",
    "        # Check if shower is done\n",
    "        if self.budget <= 0: \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return np.array(self.state).reshape(1, -1), reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset shower temperature\n",
    "        self.state = np.array([0, 0])\n",
    "        self.COVER_GRID = np.zeros([26, 26])\n",
    "        self.budget = 10000\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that our environment is working by creating an instance of it and seeing the results of randomly selected actions within the action space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allen\\anaconda3\\envs\\tf\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float64\u001b[0m\n  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = ChargeEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:3.4928971241109767\nEpisode:2 Score:4.658799051653622\nEpisode:3 Score:4.6085238319377275\nEpisode:4 Score:2.4841762060019525\nEpisode:5 Score:4.417452799463334\nEpisode:6 Score:3.771260516581514\nEpisode:7 Score:3.9643359621218455\nEpisode:8 Score:4.486344573631132\nEpisode:9 Score:3.7724118856219793\nEpisode:10 Score:2.6782335586673485\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        #env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        \n",
    "    print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown by these results, the reward varies with different actions selected, and they seem to be reasonable values to build off of and test with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q Learning Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use keras to construct the neural network for our Deep Q-Learning Agent -- the Deep Q-Network. We decided to start with one input layer, a hidden layer, and an output layer using a sequential model. The input and hidden layers use the ReLU activation function. We then build the model with our actions and states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = env.observation_space.shape\n",
    "actions = 676\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()   \n",
    "    model.add(Dense(24, activation='relu', input_shape=(2,)))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model\n",
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 24)                72        \n_________________________________________________________________\ndense_1 (Dense)              (None, 24)                600       \n_________________________________________________________________\ndense_2 (Dense)              (None, 676)               16900     \n=================================================================\nTotal params: 17,572\nTrainable params: 17,572\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown by the model summary, we now have the architecture for our Deep Q-Learning Agent. Moving forward, we will continue to obtain results from training the Q-learning and the Deep Q-Learning models, as well as add more features and complexity into our models and potentially combine the two models to tackle larger areas of New York. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Almaghrebi, A., Aljuheshi, F., Rafaie, M. et al. 2020. Data-Driven Charging Demand Prediction at Public Charging Stations Using Supervised Machine Learning Regression Methods. Energies 13(16): 4231.\n",
    "\n",
    "Flammini, M. G., Prettico, G., Andreea, J. et al. 2019. Statistical characterisation of the real transaction data gathered from electric vehicle charging stations. Electric Power Systems Research 166(1): 136-150. https://doi.org/10.1016/j.epsr.2018.09.022\n",
    "\n",
    "Gopalakrishnan, R., Biswas, A., Lightwala, A. et al. 2016. Demand Prediction and Placement Optimization for Electric Vehicle Charging Stations. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, New York, NY, July 9-15, 2016.\n",
    "\n",
    "He, J., Yang, H., Tang, T., et al. 2017. An Optimal Charging Station Location Model With The Consideration of Electric Vehicle’s Driving Range. Transportation Research Part C: Emerging Technologies 86(1): 641-654. https://doi.org/10.1016/j.trc.2017.11.026.\n",
    "\n",
    "Lam, A., Leung, Y., Chu, X., 2013. Electric vehicle charging station placement. Smart Grid communication, Oct 2013.\n",
    "\n",
    "Lee, K., A. Ahmed, M., Kang et al. 2020. Deep Reinforcement Learning Based Optimal Route and Charging Station Selection. Energies, Numerical Modeling and Machine Learning Techniques, 27 Nov 2020. https://doi.org/10.3390/en13236255.\n",
    "\n",
    "Lucas, A., Prettico, G., Flammini, M. G. et al. 2018. Indicator-Based Methodology for Assessing EV Charging Infrastructure Using Exploratory Data Analysis. Energies 11(7): 1869. https://doi.org/10.3390/en11071869. \n",
    "\n",
    "Palomino, A., Parvania, M., Zane, R., 2020. Impact of COVID-19 on Mobility and Electric Vehicle Charging Load.\n",
    "\n",
    "Prabadevi, B., Quoc-Viet, P., Madhusanka,L. et al. 2021. “Deep Learning for Intelligent Demand Response and Smart Grids: A Comprehensive Survey.” \n",
    "\n",
    "Shahraki, N., Cai, H., Turkay, M., et al. 2015. Optimal Locations of Electric Public Charging Stations Using Real World Vehicle Travel Patterns. Transportation Research Part D: Transport and Environment 44(1): 165-176. https://doi.org/10.1016/j.trd.2015.09.011.\n",
    "\n",
    "Wagner, S., Götzinger, M., Neumann, D. 2013. Optimal Location of Charging Stations in Smart Cities: A Point of Interest Based Approach. Thirty Fourth International Conference on Information Systems, Milan, Italy, 15-18 December, 2013. \n",
    "\n",
    "Zhu, Juncheng, Yang, Z., Mourshed, M., Guo, Y., Zhou, Y., Chang, Y., Wei, Y., Feng, S., 2019. Electric Vehicle Charging Load Forecasting: A Comparative Study of Deep Learning Approaches. Energies, July 2019.http://dx.doi.org/10.3390/en12142692 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
